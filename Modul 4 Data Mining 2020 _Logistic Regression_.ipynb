{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Modul 4 Data Mining 2020 \"Logistic Regression\".ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOvnXH8Rm5vI3zghCdqYDS1"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"olpVQZuamJHe","colab_type":"text"},"source":["# **Modul 4 Data Mining 2020 \"Logistic Regression\"**"]},{"cell_type":"markdown","metadata":{"id":"E2QP9Jb3mq1c","colab_type":"text"},"source":["## **What is the difference between Linear Regression and Logistic Regression?**\n","\n","Sementara Regresi Linier cocok untuk memperkirakan nilai kontinu (mis. Memperkirakan harga rumah), itu bukan alat terbaik untuk memprediksi kelas dari titik data yang diamati. Untuk memperkirakan kelas suatu titik data, kita memerlukan semacam panduan tentang apa yang akan menjadi kelas **yang paling memungkinkan** untuk titik data tersebut. Untuk itu, kita menggunakan **Logistic Regression**.\n","\n","**Ingat regresi linier:**\n","\n","Seperti yang Anda ketahui, Regresi linear menemukan fungsi yang menghubungkan variabel dependen kontinu, $ y $, ke beberapa prediktor (variabel independen $ x_1 $, $ x_2 $, dll.) Misalnya, regresi linier sederhana mengasumsikan fungsi dari:\n","<br> <br>\n","$$\n","y = w_0 + w_1 * x_1 + w_2 * x_2 + ...\n","$$\n","<br> <br>\n","dan menemukan nilai-nilai parameter $ w_0 $, $ w_1 $, $ w_2 $, dll, di mana istilah $ w_0 $ adalah \"intersep\". Secara umum dapat ditampilkan sebagai:\n","<br> <br>\n","$$\n","‚Ñé_W (ùë•) = W ^ TX\n","$$\n","<br>\n","\n","Logistic Regression adalah variasi Regresi Linier, berguna ketika variabel dependen yang diamati, $y$, adalah kategorikal. Ini menghasilkan formula yang memprediksi probabilitas label kelas sebagai fungsi dari variabel independen.\n","\n","Logistic Regression cocok dengan kurva berbentuk S khusus dengan mengambil regresi linier dan mengubah estimasi numerik menjadi probabilitas dengan fungsi berikut, yang disebut fungsi sigmoid ùúé:\n","\n","$$\n","‚Ñé_W (ùë•) = ùúé ({W ^ TX}) = \\frac {e ^ {(w_0 + w_1 * x_1 + w_2 * x_2 + ...)}} {1 + e ^ {(Œ∏_0 + w1 * x1 + w2 * x2 + ...)}}\n","$$\n","Atau:\n","$$\n","P (Y = 1 | X) = ùúé ({W ^ TX}) = \\frac {e ^ {W ^ TX}} {1 + e ^ {W ^ TX}}\n","$$\n","\n","Dalam persamaan ini, $ {W ^ TX} $ adalah hasil regresi (jumlah variabel yang ditimbang oleh koefisien), `exp` adalah fungsi eksponensial dan $ ùúé (W ^ TX) $ adalah sigmoid atau [fungsi logistik](http://en.wikipedia.org/wiki/Logistic_function), juga disebut kurva logistik. Ini adalah bentuk \"S\" yang umum (kurva sigmoid).\n","\n","Jadi, secara singkat, Logistic Regression melewati input melalui logistik / sigmoid tetapi kemudian memperlakukan hasilnya sebagai probabilitas:\n","\n","<img\n","src = \"https://ibm.box.com/shared/static/kgv9alcghmjcv97op4d6onkyxevk23b1.png\" width = \"400\" align = \"center\">\n","\n","\n","Tujuan dari algoritma __Logistic Regression__, adalah untuk menemukan parameter terbaik $ W $, untuk $ ‚Ñé_W (ùë•) = ùúé ({W ^ TX}) $, sedemikian rupa sehingga model terbaik memprediksi kelas dari setiap kasus."]},{"cell_type":"markdown","metadata":{"id":"2olpKVWFm8r9","colab_type":"text"},"source":["### **Customer churn with Logistic Regression**"]},{"cell_type":"markdown","metadata":{"id":"Qtf5EQ7wm-2k","colab_type":"text"},"source":["Sebuah perusahaan telekomunikasi prihatin dengan jumlah pelanggan yang meninggalkan bisnis sambungan telepon rumah mereka kepada pesaing yang menggunakan teknologi kabel. Mereka perlu memahami siapa yang akan pergi. Bayangkan Anda adalah seorang analis di perusahaan ini dan Anda harus mencari tahu siapa yang pergi dan mengapa."]},{"cell_type":"markdown","metadata":{"id":"tonLtFqKnASk","colab_type":"text"},"source":["### **Pertama import librarinya:**"]},{"cell_type":"code","metadata":{"id":"bR_5fJK2l9gS","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import pylab as pl\n","import numpy as np\n","import scipy.optimize as opt\n","from sklearn import preprocessing\n","%matplotlib inline \n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fLOGsD3unDl9","colab_type":"text"},"source":["### **About dataset**\n","\n","Kita akan menggunakan data telekomunikasi untuk memprediksi churn pelanggan. Ini adalah data pelanggan historis di mana setiap baris mewakili satu pelanggan. Data ini relatif mudah dipahami, dan Anda dapat mengungkap wawasan yang dapat Anda gunakan segera. Biasanya lebih murah untuk mempertahankan pelanggan daripada membeli yang baru, jadi fokus analisis ini adalah untuk memprediksi pelanggan yang akan tinggal di perusahaan.\n","\n","Kumpulan data ini menyediakan info untuk membantu Anda memprediksi perilaku mempertahankan pelanggan. Anda dapat menganalisis semua data pelanggan yang relevan dan mengembangkan program retensi pelanggan yang terfokus.\n","\n","Kumpulan data mencakup informasi tentang:\n","\n","- Pelanggan yang pergi dalam sebulan terakhir - kolom ini disebut Churn\n","- Layanan yang telah ditandatangani oleh setiap pelanggan - telepon, banyak saluran, internet, keamanan online, cadangan online, perlindungan perangkat, dukungan teknis, dan streaming TV dan film\n","- Informasi akun pelanggan - berapa lama mereka menjadi pelanggan, kontrak, metode pembayaran, penagihan tanpa kertas, biaya bulanan, dan total biaya\n","- Info demografis tentang pelanggan - jenis kelamin, rentang usia, dan jika mereka memiliki mitra dan tanggungan"]},{"cell_type":"markdown","metadata":{"id":"aRtyC5OTnK_E","colab_type":"text"},"source":["### **Download the Telco Churn data**\n","\n","Telco Churn adalah file data hipotetis yang menyangkut upaya perusahaan telekomunikasi untuk mengurangi turnover di basis pelanggannya. Setiap kasing sesuai dengan pelanggan terpisah dan mencatat berbagai informasi penggunaan layanan dan demografis. Sebelum Anda dapat bekerja dengan data, Anda harus menggunakan URL untuk mendapatkan ChurnData.csv.\n","\n","Untuk mengunduh data, kami akan menggunakan `!wget` untuk mengunduhnya dari IBM Object Storage."]},{"cell_type":"code","metadata":{"id":"AWEvI8tenJJi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":224},"outputId":"d0b207aa-134c-471c-9727-6b9d7eb9b92a","executionInfo":{"status":"ok","timestamp":1581682327064,"user_tz":-420,"elapsed":5184,"user":{"displayName":"Moch. Chamdani Mustaqim","photoUrl":"https://lh3.googleusercontent.com/-33nbQYx-djs/AAAAAAAAAAI/AAAAAAAACx4/SN7K3gZtORs/s64/photo.jpg","userId":"12782341176521372008"}}},"source":["!wget -O ChurnData.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/ChurnData.csv"],"execution_count":1,"outputs":[{"output_type":"stream","text":["--2020-02-14 12:12:11--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/ChurnData.csv\n","Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n","Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 36144 (35K) [text/csv]\n","Saving to: ‚ÄòChurnData.csv‚Äô\n","\n","\rChurnData.csv         0%[                    ]       0  --.-KB/s               \rChurnData.csv       100%[===================>]  35.30K  --.-KB/s    in 0.01s   \n","\n","2020-02-14 12:12:11 (2.93 MB/s) - ‚ÄòChurnData.csv‚Äô saved [36144/36144]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3e9KL4vfnces","colab_type":"text"},"source":["### **NOTE:** \n","Langkah selanjutnya adalah data preparation. Kita telah membahasnya dimodul sebelumnya kita disini hanya akan menyebutkan step by step data preparation tanpa coding."]},{"cell_type":"markdown","metadata":{"id":"BGuGIX43KE5p","colab_type":"text"},"source":["**1. Load Data From CSV File**"]},{"cell_type":"markdown","metadata":{"id":"gFuWoJtfKsLn","colab_type":"text"},"source":["**2. Data pre-processing and selection**\n","\n","Mari kita pilih beberapa fitur untuk pemodelan dalam kasus ini kita akan memilih fitur `tenure, age, address, income, ed, employ, equip, callcard, wireless, churn`. \n","\n","Kita juga mengubah tipe data target menjadi bilangan bulat, sebab merupakan persyaratan oleh algoritma pembelajaran scikit:"]},{"cell_type":"markdown","metadata":{"id":"6oIp6CaYNpKN","colab_type":"text"},"source":["**3. Tentukan X, dan y untuk dataset kita:**"]},{"cell_type":"markdown","metadata":{"id":"3y9OoCGINvDT","colab_type":"text"},"source":["**4. Normalisasi Dataset:**"]},{"cell_type":"markdown","metadata":{"id":"gqlbvbCMN1en","colab_type":"text"},"source":["**5. Splitting Dataset menjadi data train dan test.**"]},{"cell_type":"markdown","metadata":{"id":"87qOEzAaN86g","colab_type":"text"},"source":["### **Modeling (Logistic Regression with Scikit-learn)**"]},{"cell_type":"markdown","metadata":{"id":"ucmhlhgNOIiB","colab_type":"text"},"source":["Mari kita membangun model kita menggunakan __LogisticRegression__ dari paket Scikit-learn. Fungsi ini mengimplementasikan regresi logistik dan dapat menggunakan optimizers numerik yang berbeda untuk menemukan parameter, termasuk ‚Äònewton-cg‚Äô, ‚Äòlbfgs‚Äô, ‚Äòliblinear‚Äô, ‚Äòsag‚Äô, ‚Äòsag‚Äô, ‚Äòsaga‚Äô solver. Anda dapat menemukan informasi lengkap tentang pro dan kontra dari optimizers ini jika Anda mencarinya di internet.\n","\n","Versi Regresi Logistik dalam Scikit-learn,mendukung regularisasi. Regularisasi adalah teknik yang digunakan untuk memecahkan masalah overfitting dalam model pembelajaran mesin.\n","__C__ parameter menunjukkan __inverse kekuatan regularisasi__ yang harus menjadi float positif. Nilai yang lebih kecil menentukan regularisasi yang lebih kuat.\n","Sekarang mari kita muat model kita dengan train set:"]},{"cell_type":"code","metadata":{"id":"5d_OfDnLCNl_","colab_type":"code","outputId":"4de6e49e-c93b-491b-ec83-2cfa5f0968f4","executionInfo":{"status":"ok","timestamp":1581359660618,"user_tz":-420,"elapsed":3520,"user":{"displayName":"Moch. Chamdani Mustaqim","photoUrl":"https://lh3.googleusercontent.com/-33nbQYx-djs/AAAAAAAAAAI/AAAAAAAACx4/SN7K3gZtORs/s64/photo.jpg","userId":"12782341176521372008"}},"colab":{"base_uri":"https://localhost:8080/","height":101}},"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import confusion_matrix\n","LR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\n","LR"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n","                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n","                   multi_class='auto', n_jobs=None, penalty='l2',\n","                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n","                   warm_start=False)"]},"metadata":{"tags":[]},"execution_count":84}]},{"cell_type":"markdown","metadata":{"id":"WR8L9RVEO3pR","colab_type":"text"},"source":["Sekarang kita dapat memprediksi menggunakan set tes kami:"]},{"cell_type":"code","metadata":{"id":"ng6HvYxNCSSv","colab_type":"code","outputId":"ee7e1a6b-5e58-4613-bb9d-1007fa2af88d","executionInfo":{"status":"ok","timestamp":1581359660976,"user_tz":-420,"elapsed":3283,"user":{"displayName":"Moch. Chamdani Mustaqim","photoUrl":"https://lh3.googleusercontent.com/-33nbQYx-djs/AAAAAAAAAAI/AAAAAAAACx4/SN7K3gZtORs/s64/photo.jpg","userId":"12782341176521372008"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["yhat = LR.predict(X_test)\n","yhat"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0])"]},"metadata":{"tags":[]},"execution_count":85}]},{"cell_type":"markdown","metadata":{"id":"T0X0ieluPKdC","colab_type":"text"},"source":["__predict_proba__ mengembalikan taksiran untuk semua kelas, berdasarkan label kelas. Jadi, kolom pertama adalah probabilitas kelas 1, P (Y = 1 | X), dan kolom kedua adalah probabilitas kelas 0, P (Y = 0 | X):"]},{"cell_type":"code","metadata":{"id":"rVHsArdRCUhe","colab_type":"code","outputId":"d3ffb675-0476-494e-f111-e8033a8a27a0","executionInfo":{"status":"ok","timestamp":1581359660979,"user_tz":-420,"elapsed":2716,"user":{"displayName":"Moch. Chamdani Mustaqim","photoUrl":"https://lh3.googleusercontent.com/-33nbQYx-djs/AAAAAAAAAAI/AAAAAAAACx4/SN7K3gZtORs/s64/photo.jpg","userId":"12782341176521372008"}},"colab":{"base_uri":"https://localhost:8080/","height":353}},"source":["yhat_prob = LR.predict_proba(X_test)\n","yhat_prob"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.65, 0.35],\n","       [0.74, 0.26],\n","       [0.49, 0.51],\n","       [0.71, 0.29],\n","       [0.66, 0.34],\n","       [0.67, 0.33],\n","       [0.53, 0.47],\n","       [0.6 , 0.4 ],\n","       [0.55, 0.45],\n","       [0.68, 0.32],\n","       [0.65, 0.35],\n","       [0.58, 0.42],\n","       [0.45, 0.55],\n","       [0.69, 0.31],\n","       [0.63, 0.37],\n","       [0.5 , 0.5 ],\n","       [0.62, 0.38],\n","       [0.52, 0.48],\n","       [0.59, 0.41],\n","       [0.56, 0.44]])"]},"metadata":{"tags":[]},"execution_count":86}]},{"cell_type":"markdown","metadata":{"id":"rm_vnfVKPY5k","colab_type":"text"},"source":["### **Evaluation**"]},{"cell_type":"markdown","metadata":{"id":"RCVci1cIPali","colab_type":"text"},"source":["### jaccard index\n","\n","Mari kita coba indeks jaccard untuk evaluasi akurasi. kita dapat mendefinisikan jaccard sebagai ukuran persimpangan dibagi dengan ukuran penyatuan dua set label. Jika seluruh rangkaian label yang diprediksi untuk sampel benar-benar cocok dengan label yang benar, maka akurasi subsetnya adalah 1,0; jika tidak, itu adalah 0,0."]},{"cell_type":"code","metadata":{"id":"jxYwogz9CXdN","colab_type":"code","outputId":"94265258-716b-4bd1-a176-8b4d734246e1","executionInfo":{"status":"ok","timestamp":1581359660986,"user_tz":-420,"elapsed":1740,"user":{"displayName":"Moch. Chamdani Mustaqim","photoUrl":"https://lh3.googleusercontent.com/-33nbQYx-djs/AAAAAAAAAAI/AAAAAAAACx4/SN7K3gZtORs/s64/photo.jpg","userId":"12782341176521372008"}},"colab":{"base_uri":"https://localhost:8080/","height":87}},"source":["from sklearn.metrics import jaccard_similarity_score\n","jaccard_similarity_score(y_test, yhat)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:664: FutureWarning: jaccard_similarity_score has been deprecated and replaced with jaccard_score. It will be removed in version 0.23. This implementation has surprising behavior for binary and multiclass classification tasks.\n","  FutureWarning)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["0.85"]},"metadata":{"tags":[]},"execution_count":87}]},{"cell_type":"markdown","metadata":{"id":"cwpPkistPu4o","colab_type":"text"},"source":["### **confusion matrix**\n","\n","Cara lain untuk melihat keakuratan classifier adalah dengan melihatnya **confusion matrix.**"]},{"cell_type":"code","metadata":{"id":"jqoMs_S9CcXI","colab_type":"code","outputId":"27ebb4e5-10c2-4099-cee5-71155f3279a5","executionInfo":{"status":"ok","timestamp":1581359660988,"user_tz":-420,"elapsed":1036,"user":{"displayName":"Moch. Chamdani Mustaqim","photoUrl":"https://lh3.googleusercontent.com/-33nbQYx-djs/AAAAAAAAAAI/AAAAAAAACx4/SN7K3gZtORs/s64/photo.jpg","userId":"12782341176521372008"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["from sklearn.metrics import classification_report, confusion_matrix\n","import itertools\n","def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    Fungsi ini mencetak dan memplot matriks kebingungan.\n","¬†¬†¬†¬†Normalisasi dapat diterapkan dengan mengatur `normalize = True`.\n","    \"\"\"\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","    print(cm)\n","\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, format(cm[i, j], fmt),\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","print(confusion_matrix(y_test, yhat, labels=[1,0]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[ 2  2]\n"," [ 1 15]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"US-nzymECe_L","colab_type":"code","outputId":"91e800e1-ce47-4c55-a92b-07757fb8e36f","executionInfo":{"status":"ok","timestamp":1581359663737,"user_tz":-420,"elapsed":1878,"user":{"displayName":"Moch. Chamdani Mustaqim","photoUrl":"https://lh3.googleusercontent.com/-33nbQYx-djs/AAAAAAAAAAI/AAAAAAAACx4/SN7K3gZtORs/s64/photo.jpg","userId":"12782341176521372008"}},"colab":{"base_uri":"https://localhost:8080/","height":362}},"source":["# Hitung confusion matrix\n","cnf_matrix = confusion_matrix(y_test, yhat, labels=[1,0])\n","np.set_printoptions(precision=2)\n","\n","\n","# Plot non-normalized confusion matrix\n","plt.figure()\n","plot_confusion_matrix(cnf_matrix, classes=['churn=1','churn=0'],normalize= False,  title='Confusion matrix')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Confusion matrix, without normalization\n","[[ 2  2]\n"," [ 1 15]]\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAU8AAAEmCAYAAADiNhJgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"7ZtT7z8fQmWK","colab_type":"text"},"source":["Lihatlah baris pertama. Baris pertama adalah untuk pelanggan yang nilai churn sebenarnya dalam set tes adalah 1. Seperti yang Anda dapat menghitung, dari 40 pelanggan, nilai churn dari 15 dari mereka adalah 1. Dan dari 15 ini, classifier memprediksi dengan benar 6 dari mereka sebagai 1 dan 9 dari mereka sebagai 0.\n","\n","Ini berarti, untuk 6 pelanggan, nilai churn yang sebenarnya adalah 1 pada set tes, dan classifier juga dengan benar memprediksi mereka sebagai 1. Namun, sementara label sebenarnya dari 9 pelanggan adalah 1, classifier memperkirakan mereka sebagai 0, yang tidak terlalu baik. Kita dapat menganggapnya sebagai kesalahan model untuk baris pertama.\n","\n","Bagaimana dengan pelanggan dengan nilai churn 0? Mari kita lihat baris kedua. Sepertinya ada 25 pelanggan yang nilai churnnya 0.\n","\n","Pengklasifikasi secara benar memprediksi 24 dari mereka sebagai 0, dan salah satunya salah sebagai 1. Jadi, ia telah melakukan pekerjaan yang baik dalam memprediksi pelanggan dengan nilai churn 0. Hal yang baik tentang matriks kebingungan adalah yang menunjukkan kemampuan model untuk secara benar memprediksi atau memisahkan kelas. Dalam kasus spesifik dari penggolong biner, seperti contoh ini, kita dapat menginterpretasikan angka-angka ini sebagai jumlah **true positives, false positives, true negatives, and false negatives.**"]},{"cell_type":"code","metadata":{"id":"1TeK3BdsChjV","colab_type":"code","outputId":"aa8a95c5-0114-491c-a387-51461b20b734","executionInfo":{"status":"ok","timestamp":1581359663740,"user_tz":-420,"elapsed":1244,"user":{"displayName":"Moch. Chamdani Mustaqim","photoUrl":"https://lh3.googleusercontent.com/-33nbQYx-djs/AAAAAAAAAAI/AAAAAAAACx4/SN7K3gZtORs/s64/photo.jpg","userId":"12782341176521372008"}},"colab":{"base_uri":"https://localhost:8080/","height":168}},"source":["print (classification_report(y_test, yhat))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.88      0.94      0.91        16\n","           1       0.67      0.50      0.57         4\n","\n","    accuracy                           0.85        20\n","   macro avg       0.77      0.72      0.74        20\n","weighted avg       0.84      0.85      0.84        20\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6NR5kHW7RHeM","colab_type":"text"},"source":["Berdasarkan hitungan masing-masing bagian,kita dapat menghitung precision dan recall setiap label:\n","\n","\n","- __Precision__ adalah ukuran accuracy asalkan label kelas telah diprediksi. Ini didefinisikan oleh: presisi = TP / (TP + FP)\n","\n","- __Recall__ adalah tingkat true positive. Ini didefinisikan sebagai: Ingat = TP / (TP + FN)\n","\n","¬†¬†¬†¬†\n","Jadi, kita bisa menghitung precision dan recall masing-masing kelas.\n","\n","- __F1 score:__\n","Sekarang kita berada dalam posisi untuk menghitung skor F1 untuk setiap label berdasarkan precision dan recall label itu.\n","\n","**F1score** adalah rata-rata harmonik dari precision dan recall, di mana skor F1 mencapai nilai terbaiknya di 1 (precision dan recall sempurna) dan terburuk di 0. Ini adalah cara yang baik untuk menunjukkan bahwa classifier memiliki nilai yang baik untuk kedua precision dan recall.\n","\n","\n","Dan akhirnya, kita dapat mengetahui akurasi rata-rata untuk pengklasifikasi ini adalah rata-rata skor f1 untuk kedua label, yaitu 0,72 dalam kasus kami."]},{"cell_type":"markdown","metadata":{"id":"gRrtEGF-SG-Z","colab_type":"text"},"source":["### **log loss**\n","\n","Sekarang, mari kita coba __log loss__ untuk evaluasi. Dalam regresi logistik, output bisa menjadi probabilitas pelanggan churn adalah ya (atau sama dengan 1). Probabilitas ini adalah nilai antara 0 dan 1.\n","Log loss (Logarithmic loss) mengukur kinerja classifier di mana output yang diprediksi adalah nilai probabilitas antara 0 dan 1."]},{"cell_type":"code","metadata":{"id":"oSNIb6ucClIZ","colab_type":"code","outputId":"4740c871-ce7a-4452-d197-64be4544638c","executionInfo":{"status":"ok","timestamp":1581359665671,"user_tz":-420,"elapsed":919,"user":{"displayName":"Moch. Chamdani Mustaqim","photoUrl":"https://lh3.googleusercontent.com/-33nbQYx-djs/AAAAAAAAAAI/AAAAAAAACx4/SN7K3gZtORs/s64/photo.jpg","userId":"12782341176521372008"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from sklearn.metrics import log_loss\n","log_loss(y_test, yhat_prob)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5395588837253594"]},"metadata":{"tags":[]},"execution_count":91}]}]}